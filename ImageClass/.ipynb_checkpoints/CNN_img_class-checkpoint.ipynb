{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clasificación de Imagenes Desde Cero\n",
    "## ¿Qué es la Clasificación de Imagenes?\n",
    "La clasificación de imágenes es la tarea donde se utiliza visión por computador y algoritmos de aprendizaje automático para extraer la idea de una imagen. Esta tarea puede ser tan simple como asignar una etiqueta dependiendo del contenido de una imagen o tan compleja como interpretar el contenido de una imagen y devolver una frase legible para un humano.\n",
    "\n",
    "La clasificación de imágenes y la comprensión de las imágenes son actualmente y continuará siendo el sub campo más popular de visión por computadora. Hoy en día vemos más aplicaciones, por ejemplo, en el celular, que pueden interpretar y entender el contenido de una imagen. Incluso en las guerras se están viendo aviones no tripulados guiados mediante algoritmos de visión por computador.\n",
    "\n",
    "La tarea de clasificación de imágenes consiste básicamente en analizar una imagen de entrada y devolver una etiqueta que categoriza la imagen. Las etiquetas siempre están en un conjunto previamente definido.\n",
    "\n",
    "Nuestro sistema de clasificación podría también asignar múltiples etiquetas mediante probabilidades de pertenencia. Dada una imagen de entrada de HxW píxeles con tres canales rojo, verde y azul, nuestro objetivo es tomar los N pixeles y averiguar cómo clasificar correctamente el contenido de la imagen.\n",
    "\n",
    "Un computador ve una imagen como una matriz de pixeles. Los computadores no tienen idea del contenido de una imagen, por ejemplo, si es un gato o un perro, para él es indistinto. El objetivo es que un computador pueda entender el contenido de información de la imagen. Para lograr esto, necesitamos aplicar la extracción de características. Este es el proceso de tomar una imagen de entrada, aplicar un algoritmo y obtener un vector de características (un arreglo de números) que cuantifiquen nuestra imagen.\n",
    "\n",
    "Para completar este proceso, podemos considerar aplicar algoritmos de extracción de características manuales como HOG, LBPs, u otros algoritmos tradicionales. Otro método es aplicar técnicas de aprendizaje profundo para automáticamente aprender un conjunto de características que pueden ser usadas para cuantificar y etiquetar el contenido de una imagen.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conjunto de Datos para el Ejemplo\n",
    "El conjunto de datos que utilizaremos para desarrollar este tutorial es el Fashion MNIST clothing Classification. Este conjunto de datos relativamente sencillo consiste de aproximadamente 60000 imágenes de 20x20 en escala de grises. Tenemos 10 clases de ropa para clasificar:\n",
    "\n",
    "- 0: Camiseta/top\n",
    "- 1: Pantalones\n",
    "- 2: Jersey\n",
    "- 3: Vestido\n",
    "- 4: Abrigo\n",
    "- 5: Sandalia\n",
    "- 6: Camisa\n",
    "- 7: Zapatilla de deporte\n",
    "- 8: Bolso\n",
    "- 9: Botín\n",
    "\n",
    "Este problema es más retador que el clásico problema de dígitos de MNIST. Los mejores resultados para este conjunto de datos están entre 90% – 95% con el conjunto de datos de prueba.\n",
    "\n",
    "Para el desarrollo de nuestro modelo tenemos básicamente cinco etapas, cargar el conjunto de datos, preparar los datos, definición del modelo, entrenamiento del modelo y presentación de resultados.\n",
    "\n",
    "En la primera celda indicamos todas las librerías que utilizaremos para el desarrollo del proyecto. Básicamente utilizaremos Keras, Numpy y Matplotlib:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "#from sklearn.model_selection import KFold\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout, Conv2D,\\\n",
    "    MaxPooling2D, BatchNormalization\n",
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "from tensorflow.keras.utils import to_categorical, plot_model\n",
    "from tensorflow.keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primero vamos a cargar el conjunto de datos, este es popular y relativamente simple. Así que se puede utilizar como base para aprender y practicar como desarrollar, entrenar, evaluar y usar una red neuronal para clasificación de imágenes. Este conjunto de datos está incluido dentro de la librería Keras.\n",
    "\n",
    "Como sabemos en cada imagen solo aparece una prenda de vestir, todas las imágenes están en escala de grises y tienen el mimo tamaño de 28x28 pixeles. Entonces vamos a establecer que los datos de entrada tienen un solo canal de color.\n",
    "\n",
    "Los valores de cada pixel en la imagen son enteros sin signo entre 0 – 255. Como habíamos mencionado antes tenemos un solo canal, por lo cual la imagen varía entre el blanco y el negro. Vamos a normalizar los valores de los pixeles de la imagen entre [0,1]. Estos datos se almacenarán como flotantes, el procedimiento consiste simplemente en dividir el arreglo de pixeles entre el máximo (255)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "BS = 32\n",
    "EPOCHS = 5\n",
    "\n",
    "#load dataset\n",
    "(trainX, trainY), (testX, testY) = fashion_mnist.load_data()\n",
    "\n",
    "#reshape\n",
    "trainX = trainX.reshape((trainX.shape[0], 28, 28, 1))\n",
    "testX = testX.reshape((testX.shape[0], 28, 28, 1))\n",
    "\n",
    "#normalize\n",
    "trainX = np.array(trainX, dtype=\"float32\") / 255.0\n",
    "testX = np.array(testX, dtype=\"float32\") / 255.0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este es un problema de clasificación multiobjetivo, donde tenemos 10 clases de objetos. Como se ha mencionado estos datos vienen codificados como entero, sin embargo, para el entrenamiento de redes neuronales se debe utilizar la salida codificada en binario. Este es el conocido codificador “one-hot”, vamos a implementarlo con la clase to_categorical de keras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#one hot encoder\n",
    "trainY = to_categorical(trainY)\n",
    "testY = to_categorical(testY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#probamos aumentar los datos\n",
    "aug = ImageDataGenerator(rotation_range=25, width_shift_range=0.1,\n",
    "\theight_shift_range=0.1, shear_range=0.2, zoom_range=0.2,\n",
    "\thorizontal_flip=True, fill_mode=\"nearest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora necesitamos definir un modelo de red neuronal. En este caso vamos a utilizar las siguientes capas: convolucionales, normalización de batch, max pooling, aplanado (flatten), totalmente conectada (Dense), dropout.\n",
    "\n",
    "Para las capas convolucionales podemos empezar con una capa simple o con capas apiladas. En este caso utilizaremos varias capas convolucionales con un número de filtros entre [8,32]. El tamaño del kernel será fijo de (3x3), utilizaremos el relleno adecuado (same) y en todos los casos la función de activación será de tipo ReLU. Posterior a las capas convolucionales podemos usar una capa de normalización de batch y adicionalmente capas de pooling (agrupación) de (2x2) tomando el máximo argumento.\n",
    "\n",
    "Dado que estamos trabajando con un problema de clasificación multiobjetivo, debemos establecer la salida adecuada, en este caso utilizaremos una capa Softmax. Esta capa de salida totalmente conectada nos entrega la probabilidad de que un ejemplo pertenezca a cada una de las clases.\n",
    "\n",
    "Para poder conectar las capas convolucionales con la capa de salida, se deben adecuar las señales. Para esto primero utilizamos una capa de aplanado, la cual nos permite tener un arreglo en forma de vector con base en las salidas bidimensionales de las capas convolucionales. Posteriormente utilizamos una capa totalmente conectada que nos ayudará a extraer ciertas características. Adicionalmente utilizaremos una capa de dropout entre la capa totalmente conectada y la capa de salida. La capa de dropout elimina sinapsis de forma aleatoria con cierta probabilidad, con el objetivo de limitar el sobre ajuste a los datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 28, 28, 8)         80        \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 28, 28, 8)         32        \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 14, 14, 8)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 14, 14, 16)        1168      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 14, 14, 16)        64        \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 14, 14, 16)        2320      \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 14, 14, 16)        64        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 7, 7, 16)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 50)                39250     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                510       \n",
      "=================================================================\n",
      "Total params: 43,488\n",
      "Trainable params: 43,408\n",
      "Non-trainable params: 80\n",
      "_________________________________________________________________\n",
      "('Failed to import pydot. You must `pip install pydot` and install graphviz (https://graphviz.gitlab.io/download/), ', 'for `pydotprint` to work.')\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "inputShape = trainX.shape[1:4]\n",
    "chanDim = -1\n",
    "model.add(Conv2D(8, (3, 3), padding='same', activation='relu',\n",
    "                 kernel_initializer='he_uniform', input_shape=inputShape))\n",
    "model.add(BatchNormalization(axis=chanDim))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(Conv2D(16, (3, 3), padding='same', activation='relu',\n",
    "                 kernel_initializer='he_uniform'))\n",
    "model.add(BatchNormalization(axis=chanDim))\n",
    "\n",
    "model.add(Conv2D(16, (3, 3), padding='same', activation='relu',\n",
    "                 kernel_initializer='he_uniform'))\n",
    "model.add(BatchNormalization(axis=chanDim))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(50, activation='relu', kernel_initializer='he_uniform'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(trainY.shape[1], activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "plot_model(model, to_file='model_plot.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez hemos definido el modelo, que en este caso es secuencial, definimos el optimizador que deseamos utilizar para el entrenamiento. Compilamos el modelo, en este caso utilizamos la función de perdida de entropía cruzada categórica dada la naturaleza de clasificación multiclase del problema. Queremos utilizar la métrica de “accuracy” para validar nuestro modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = SGD(lr=0.01, momentum=0.9)\n",
    "\n",
    "model.compile(optimizer=opt, loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El siguiente paso es entrenar el modelo, definimos los datos de entrenamiento y validación, el número de épocas de entrenamiento, ponemos la bandera de “verbose” en true para tener idea de cómo va el entrenamiento del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the network\n",
    "print(\"[INFO] training network...\")\n",
    "H = model.fit_generator(aug.flow(trainX, trainY, batch_size=BS),\n",
    "\tvalidation_data=(testX, testY), steps_per_epoch=len(trainX) // BS,\n",
    "\tepochs=EPOCHS, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con el objetivo de visualizar los datos del proceso de entrenamiento, graficamos los datos correspondientes al “accuracy” y “loss” tanto para los datos de entrenamiento, como para los datos de prueba. De esta manera podemos verificar si en algún momento el modelo tiene sobreajuste a los datos, además de verificar el rendimiento general del planteamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = EPOCHS\n",
    "plt.plot(np.arange(0, N), H.history[\"loss\"], label=\"train_loss\")\n",
    "plt.plot(np.arange(0, N), H.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.plot(np.arange(0, N), H.history[\"accuracy\"], label=\"train_acc\")\n",
    "plt.plot(np.arange(0, N), H.history[\"val_accuracy\"], label=\"val_acc\")\n",
    "plt.title(\"Training Loss and Accuracy\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Loss/Accuracy\")\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
