{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from adtk.visualization import plot\n",
    "from adtk.data import validate_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('TEMP_selected.csv', names=['muestra','temp'], delimiter=';')\n",
    "data = data.drop(data.index[[0]])\n",
    "data.set_index(\n",
    "    pd.PeriodIndex(np.array(data.muestra), freq=\"10min\"),\n",
    "    inplace=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(\"muestra\", axis=1, inplace=True)\n",
    "\n",
    "data['temp']= data['temp'].str.replace(',','.')\n",
    "data['temp']= data['temp'].astype(float)\n",
    "\n",
    "data.index = data.index.to_timestamp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['temp'] = data['temp'].fillna(0)\n",
    "\n",
    "print(data['temp'].isnull().sum())\n",
    "\n",
    "plot(data)\n",
    "\n",
    "orig_data = data.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Árboles de Decisión: Isolation Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "data = orig_data.copy()\n",
    "orig_index = data.index\n",
    "\n",
    "outlier_frac= 0.05\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "np_scaled = scaler.fit_transform(data.values.reshape(-1,1))\n",
    "data = pd.DataFrame(np_scaled, index=orig_index, columns=['temp'])\n",
    "\n",
    "model = IsolationForest(contamination=outlier_frac)\n",
    "model.fit(data)\n",
    "\n",
    "data['anomaly'] = model.predict(data)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,6))\n",
    "a = data.loc[data['anomaly'] == -1, ['temp']] #anomaly\n",
    "ax.plot(data.index, data['temp'], color='black', label = 'Normal')\n",
    "ax.scatter(a.index,a['temp'], color='red', label = 'Anomaly')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicción: fbprophet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fbprophet import Prophet\n",
    "\n",
    "def detect_anomalies(forecast):\n",
    "    forecasted = forecast[['ds','trend', 'yhat', 'yhat_lower', 'yhat_upper', 'fact']].copy()\n",
    "\n",
    "    forecasted['anomaly'] = 0\n",
    "    forecasted.loc[forecasted['fact'] > forecasted['yhat_upper'], 'anomaly'] = 1\n",
    "    forecasted.loc[forecasted['fact'] < forecasted['yhat_lower'], 'anomaly'] = -1\n",
    "\n",
    "    #anomaly importances\n",
    "    forecasted['importance'] = 0\n",
    "    forecasted.loc[forecasted['anomaly'] ==1, 'importance'] = \\\n",
    "        (forecasted['fact'] - forecasted['yhat_upper'])/forecast['fact']\n",
    "    forecasted.loc[forecasted['anomaly'] ==-1, 'importance'] = \\\n",
    "        (forecasted['yhat_lower'] - forecasted['fact'])/forecast['fact']\n",
    "    \n",
    "    return forecasted\n",
    "\n",
    "data = pd.DataFrame()\n",
    "data['ds'] = orig_data.index\n",
    "data['y'] = orig_data.values\n",
    "\n",
    "interval_width = 0.99\n",
    "changepoint_range = 0.95\n",
    "\n",
    "m = Prophet(daily_seasonality = False, yearly_seasonality = False,\n",
    "            weekly_seasonality = False, seasonality_mode = 'additive',\n",
    "            interval_width = interval_width,\n",
    "            changepoint_range = changepoint_range)\n",
    "\n",
    "m = m.fit(data)\n",
    "pred = m.predict(data)\n",
    "pred['fact'] = data['y'].reset_index(drop = True)\n",
    "\n",
    "pred = detect_anomalies(pred)\n",
    "\n",
    "print(np.count_nonzero(pred['anomaly'].values))\n",
    "\n",
    "norm = pred[['ds','trend', 'yhat', 'yhat_lower', 'yhat_upper']].copy()\n",
    "\n",
    "m.plot(norm)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,6))\n",
    "a = pred.loc[pred['anomaly'] != 0,['ds','fact']] #anomaly\n",
    "ax.scatter(pred['ds'], pred['fact'], color='black', label = 'Normal')\n",
    "ax.scatter(a['ds'],a['fact'], color='red', label = 'Anomaly')\n",
    "ax.scatter(pred['ds'],pred['yhat'], color='cyan', label = 'Forecasted')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agrupaciones\n",
    "### K-Means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "def getDistanceByPoint(data, model):\n",
    "    \"\"\" Function that calculates the distance between a point and centroid of a cluster, \n",
    "            returns the distances in pandas series\"\"\"\n",
    "    distance = []\n",
    "    for i in range(0,len(data)):\n",
    "        Xa = np.array(data.iloc[i][0])\n",
    "        Xb = model.cluster_centers_[model.labels_[i]-1]\n",
    "        distance.append(np.linalg.norm(Xa-Xb))\n",
    "    return pd.Series(distance, index=data.index)\n",
    "\n",
    "data = orig_data.copy()\n",
    "outlier_frac = 0.05\n",
    "\n",
    "n_cluster = range(1,20)\n",
    "\n",
    "kmeans = [KMeans(n_clusters=i).fit(data.values) for i in n_cluster]\n",
    "scores = [kmeans[i].score(data.values) for i in range(len(kmeans))]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,6))\n",
    "ax.plot(n_cluster, scores)\n",
    "plt.xlabel('Number of Clusters')\n",
    "plt.ylabel('Score')\n",
    "plt.title('Elbow Curve')\n",
    "plt.show();\n",
    "\n",
    "labels = kmeans[7].predict(data.values)\n",
    "uniq_elem, count_elem = np.unique(labels, return_counts=True)\n",
    "\n",
    "clusters = np.asanyarray((uniq_elem,count_elem))\n",
    "\n",
    "distance = getDistanceByPoint(data, kmeans[7])\n",
    "\n",
    "num_outlier = int(outlier_frac*len(distance))\n",
    "\n",
    "threshold = distance.nlargest(num_outlier).min()\n",
    "\n",
    "data['anomaly'] = (distance >= threshold).astype(int)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,6))\n",
    "a = data.loc[data['anomaly'] == 1, ['temp']] #anomaly\n",
    "ax.plot(data.index, data['temp'], color='black', label = 'Normal')\n",
    "ax.scatter(a.index,a['temp'], color='red', label = 'Anomaly')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "data = orig_data.copy()\n",
    "\n",
    "dbscan = DBSCAN(eps=0.05, min_samples=10).fit(data.values)\n",
    "labels = dbscan.labels_\n",
    "outlier_pos = np.where(labels == -1)[0] #indice\n",
    "\n",
    "a = data.iloc[outlier_pos]\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,6))\n",
    "ax.scatter(data.index, data['temp'], color='black', label = 'Normal')\n",
    "ax.scatter(a.index, a['temp'], color='red', label = 'Anomaly')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
